{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08b2ae6",
   "metadata": {},
   "source": [
    "# Workshop 2025-W49 - Predicting survivors on the Titanic\n",
    "\n",
    "This workshop will be focused on predicting which passengers aboard the Titanic survived. It will based on the classic Titanic dataset, which we have taken from [Kaggle](https://www.kaggle.com/competitions/titanic/). Following the link you can find more information about the different columns of the dataset, as well as how others have analyzed it.\n",
    "\n",
    "This dataset is presented in its raw form here, which means we will have to do some EDA and data cleaning in order to use it for prediction and analysis. Additionally, depending on model choice, we might have to encode our categorical features (that is, transform them into numerical representations).\n",
    "\n",
    "**Important**\n",
    "Try to pick one particular thing to explore in this workshop, at least initially. It is easy to get overwhelmed when there are many things to do and also to simply underestimate how much time certain tasks take. This rings especially true for the intermediate and advanced level tasks.\n",
    "\n",
    "**Beginner level:**\n",
    "A very important and often first step when working with data is to get a good overview of the data and start exploring it. If you do not have much experience with data analysis, this is a great way to begin learning about the [pandas](https://pandas.pydata.org/docs/getting_started/index.html#getting-started) and [matplotlib](https://matplotlib.org/stable/users/index.html) libraries. Below are some ideas if you need inspiration, but feel free to explore whatever question you come up with.\n",
    "- How does age, sex, and ticket class relate to survivability? Showing these relations are not trivial, so an initial idea could be to plot histograms with the average survival rate within each group.\n",
    "- Check for missing values. Do you notice anything strange? Do you think the missing value here contains important information?\n",
    "- Come up with a question or hypothesis and try to answer/test it using the data.\n",
    "\n",
    "**Intermediate level:**\n",
    "At the intermediate level, we might want to start predicting whether passengers survived or not.\n",
    "\n",
    "- For prediction we might need to handle categorical columns and missing data depending on our choice of model. Techniques for handling this are called encoding and imputation methods respectively and there are a wide variety of them. You can read more about basic imputation [here](https://www.kaggle.com/code/alexisbcook/missing-values) and about basic encoding [here](https://www.kaggle.com/code/alexisbcook/categorical-variables).\n",
    "- Picking/creating a suitable family of models often depends on the problem at hand. For tabular data, a classic first choice is some variant of a gradient boosting machine (GBM). The most common ones are [XGBoost](https://xgboost.readthedocs.io/en/stable/), [CatBoost](https://catboost.ai/docs/en/), and [LightGBM](https://lightgbm.readthedocs.io/en/stable/). Pick one, split the data into train/test, and see if you can get a good classification accuracy on the unseen data.\n",
    "- One way of improving a model's predictions, or discovering new relationships between our features/explanatory variables, is through feature engineering. Roughly speaking, feature engineering is the art of creating new, potentially strong features based on our given features. See if you can find new features that give better performance of your chosen model. You can read more [here](https://www.kaggle.com/learn/feature-engineering).\n",
    "\n",
    "**Advanced level:**\n",
    "Now we want to dive deeper into a specific case based on the data. Predicting survivability is cool, but at the end of the day, that prediction does not mean much by itself. We are not exactly going to be getting any new unseen data to predict survivability on in the future. Instead, a better question to ask in our case is _why_ certain people survived. This is actually a fairly deep question that is **very** difficult to answer. Therefore we will tackle it from a slightly different angle. Instead of trying to find causal relationships in the data, we instead try to figure out why our model makes the predictions it does.\n",
    "- A more rigorous way of concluding a relationship between our output (survival status) and our explanatory variables is through a simple logistic regression. One would have to handle the categorical variables (probably through one-hot encoding). A problem that commonly arises when doing regression analysis for inferece is that of [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity). Is that a problem in our dataset?\n",
    "- With more complex data, we may often not be satisfied with the performance of a relatively simple model like logistic regression. A lot of GBM-libraries have built-in feature importance modules that let us view which of our features are most important for prediction. This could give us a hint as to what is important for a person to survive the sinking of the Titanic.\n",
    "- Feature importance is nice, but leaves a lot to be desired. It does not have the statistical properties of the logistic regression and also does not tell us how certain features impact our predictions. A new and super popular library for this (that works for a lot of models suffering from this issue, not just GBMs) is [SHAP](https://shap.readthedocs.io/en/latest/). See if you can implement this on a fitted XGBoost model and get some nice plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92755e6a",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b8fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "PATH = 'titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d7bce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2a468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
